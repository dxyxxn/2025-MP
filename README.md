# LectureAI - 강의 음성 및 PDF 자동 처리 시스템

강의 오디오 파일과 PDF 자료를 업로드하면, AI가 자동으로 음성을 텍스트로 변환하고, 강의 내용을 요약하며, PDF와 음성 스크립트를 의미 기반으로 매핑하는 지능형 학습 지원 시스템입니다.

## 기술 스택

### 백엔드
- **Django 5.2.7**: 웹 프레임워크
- **Celery**: 비동기 작업 처리
- **Redis**: 메시지 브로커 및 결과 저장소
- **SQLite**: 관계형 데이터베이스

### AI/ML 서비스
- **Google Gemini API**: 
  - STT (Speech-to-Text): 오디오를 텍스트로 변환
  - 텍스트 요약: 강의 스크립트를 소주제별로 요약
  - 텍스트 임베딩: 의미 기반 검색을 위한 벡터 생성
- **Ollama (로컬 LLM)**:
  - PDF 이미지 분석: bakllava 멀티모달 모델을 사용하여 PDF 내 이미지, 다이어그램, 차트 분석
  - 로컬 실행으로 API 비용 절감 및 처리 속도 향상

### 벡터 데이터베이스
- **ChromaDB**: PDF와 스크립트의 임베딩 벡터를 저장하여 의미 기반 검색 지원

### 프론트엔드
- **Bootstrap 5**: 반응형 UI 프레임워크
- **PDF.js**: PDF 파일 렌더링
- **Marked.js**: 마크다운 렌더링 (AI 응답 표시용)

### 유틸리티
- **PyMuPDF (fitz)**: PDF 파싱 및 텍스트 추출
- **Ollama**: 로컬 멀티모달 LLM 실행 (bakllava 모델)
- **mutagen/ffprobe/pydub**: 오디오 파일 길이 측정

## 주요 기능

### 1. 사용자 인증
- 회원가입 및 로그인
- 사용자별 강의 데이터 관리

### 2. 강의 파일 업로드
- 오디오 파일 업로드 (음성 강의)
- PDF 파일 업로드 (강의 자료)
- 예상 소요 시간(ETR) 자동 계산 및 표시

### 3. 자동 처리 파이프라인 (병렬 처리 최적화)
강의 파일이 업로드되면 다음 4단계가 **병렬 처리**를 통해 자동으로 실행됩니다:

#### 병렬 그룹 1: STT 처리 + PDF 파싱 (동시 실행)
- **STT 처리**: 오디오 파일을 Gemini API를 통해 텍스트로 변환 (타임스탬프 포함)
- **PDF 파싱**: 
  - **하이브리드 방식**: PyMuPDF로 페이지 텍스트를 정확하고 빠르게 추출
  - 페이지에서 이미지 객체 추출
  - 각 이미지를 Ollama bakllava 모델로 분석 (영어 설명, 타임아웃 및 재시도 포함)
  - 텍스트와 이미지 설명을 결합하여 완전한 페이지 내용 생성
- 두 작업이 **동시에 실행**되어 전체 처리 시간 단축
- 각 작업 완료 시 소요 시간 표시

#### 병렬 그룹 2: 요약 생성 + 임베딩 (동시 실행)
- **스크립트 요약 생성**: 전체 스크립트를 Gemini API로 분석하여 소주제별로 구조화된 요약 생성
  - 각 소주제에 대한 핵심 내용, 원본 구간, 타임스탬프 정보 포함
- **임베딩 및 벡터 DB 저장**:
  - PDF 페이지와 스크립트를 청크 단위로 분할
  - 각 청크를 Gemini Embedding API로 벡터화
  - ChromaDB에 저장하여 의미 기반 검색 가능하도록 구성
- 두 작업이 **동시에 실행**되어 전체 처리 시간 단축
- 각 작업 완료 시 소요 시간 표시

#### 순차 처리 1: 의미 기반 매핑
- 요약의 각 소주제를 PDF의 해당 페이지와 의미적으로 매핑
- 벡터 유사도 검색을 통해 가장 관련성 높은 PDF 페이지 자동 연결
- 소요 시간 표시

#### 순차 처리 2: 데이터 저장
- 처리된 모든 데이터를 데이터베이스에 저장
- PdfChunk 및 Mapping 모델에 저장
- 사용자가 학습 페이지에서 접근 가능하도록 준비
- 소요 시간 표시

### 4. 학습 페이지
- **PDF 뷰어**: 강의 자료를 페이지별로 표시
- **음성 스크립트**: 타임스탬프가 포함된 전체 스크립트 표시
- **소주제별 요약**: 아코디언 형태로 요약 내용 표시 (PDF 페이지 번호 포함)
- **RAG 챗봇**: 강의 내용에 대한 질문에 AI가 답변 (벡터 검색 기반)

### 5. 예상 소요 시간(ETR) 시스템
- 업로드 시 오디오 길이와 PDF 페이지 수를 기반으로 처리 시간 예측
- **병렬 처리 구조 반영**: 각 병렬 그룹에서 가장 긴 작업 시간을 사용하여 정확한 예측
  - 병렬 그룹 1: max(STT 예상 시간, PDF 파싱 예상 시간)
  - 병렬 그룹 2: max(요약 예상 시간, 임베딩 예상 시간)
- 과거 처리 통계를 학습하여 점진적으로 정확도 향상
- 이동 평균 방식으로 통계 업데이트 (기존 50%, 새 50%)
- 개별 통계 추적: STT, PDF 파싱, 임베딩, 요약 각각의 평균 시간을 별도로 관리

## 애플리케이션 워크플로우

### 1. 사용자 인증 흐름
```
사용자 접속 → 로그인/회원가입 → 인증 완료 → 업로드 페이지
```

### 2. 파일 업로드 및 처리 흐름
```
파일 업로드 (오디오 + PDF)
    ↓
데이터베이스에 강의 정보 저장
    ↓
ETR 계산 태스크 시작 (비동기, 빠른 계산)
    ↓
처리 중 페이지로 즉시 리다이렉트
    ↓
Celery 백그라운드 작업 시작
    ├─ 병렬 그룹 1 (동시 실행):
    │   ├─ STT 처리 (오디오 → 텍스트)
    │   └─ PDF 파싱 및 텍스트 추출 (PyMuPDF + Ollama 이미지 분석)
    ├─ 병렬 그룹 2 (동시 실행):
    │   ├─ 요약 생성 (소주제별 구조화)
    │   └─ 임베딩 생성 및 ChromaDB 저장
    ├─ 순차 처리:
    │   ├─ 의미 기반 매핑 (요약 ↔ PDF 페이지)
    │   └─ 데이터 저장
    └─ 처리 통계 업데이트 (ETR 예측 정확도 향상)
    ↓
처리 완료 → 학습 페이지로 자동 이동
```

### 3. 학습 페이지 사용 흐름
```
학습 페이지 접속
    ├─ PDF 뷰어: 강의 자료 확인
    ├─ 스크립트: 타임스탬프별 음성 내용 확인
    ├─ 요약본: 소주제별 핵심 내용 확인 (PDF 페이지 링크 포함)
    └─ RAG 챗봇: 강의 내용에 대한 질문 및 답변
```

### 4. PDF 처리 방식 (하이브리드)
```
PDF 페이지 처리
    ↓
PyMuPDF로 텍스트 추출 (정확하고 빠름)
    ↓
페이지에서 이미지 객체 추출
    ↓
각 이미지를 Ollama bakllava로 분석
    ├─ 이미지 내용 설명 (영어)
    ├─ 다이어그램, 차트 분석
    └─ 수식 및 시각적 요소 설명
    ↓
텍스트 + 이미지 설명 결합
    ↓
최종 페이지 내용 생성
```

### 5. RAG 챗봇 동작 흐름
```
사용자 질문 입력
    ↓
질문을 임베딩 벡터로 변환
    ↓
ChromaDB에서 유사한 문서 검색 (PDF 페이지 또는 스크립트)
    ↓
검색된 컨텍스트와 질문을 Gemini에 전달
    ↓
AI가 컨텍스트 기반 답변 생성
    ↓
사용자에게 답변 표시 (마크다운 렌더링)
```

## 데이터 모델 구조

### 핵심 모델
- **CustomUser**: 사용자 계정 정보
- **Lecture**: 강의 메타데이터 및 처리 상태
  - `current_step`: 현재 처리 단계 (0, 1, 3, 5, 6 - 병렬 구조 반영)
  - `step_times`: 단계별 소요 시간 (JSON 형식)
  - `estimated_time_sec`: 예상 소요 시간(초, 병렬 구조 기반 계산)
- **PdfChunk**: PDF 페이지별 텍스트 내용 (텍스트 + 이미지 설명 포함)
- **Mapping**: 요약 소주제와 PDF 페이지의 의미 기반 매핑
- **ProcessingStats**: 처리 속도 통계 (ETR 예측용)
  - `audio_stt_avg_sec_per_min`: STT 평균 시간 (초/분)
  - `pdf_parsing_avg_sec_per_page`: PDF 파싱 평균 시간 (초/페이지)
  - `embedding_avg_sec_per_page`: 임베딩 평균 시간 (초/페이지)
  - `summary_avg_sec`: 요약 평균 시간 (초)
  - `pdf_processing_avg_sec_per_page`: PDF 전체 처리 평균 (하위 호환성)

## 시스템 아키텍처

```
┌─────────────┐
│   사용자     │
└──────┬──────┘
       │
       ▼
┌─────────────────┐
│  Django 서버    │
│  (웹 인터페이스) │
└──────┬──────────┘
       │
       ├─────────────────┐
       │                 │
       ▼                 ▼
┌─────────────┐   ┌──────────────┐
│   SQLite    │   │   Celery     │
│  (메타데이터)│   │  (비동기 작업)│
└─────────────┘   └──────┬───────┘
                         │
                         ▼
                  ┌──────────────┐
                  │    Redis     │
                  │ (작업 큐)    │
                  └──────────────┘
                         │
                         ├─────────────────┐
                         │                 │
                         ▼                 ▼
                  ┌──────────────┐   ┌──────────────┐
                  │  Gemini API  │   │   Ollama     │
                  │ (STT/요약/   │   │ (로컬 LLM)   │
                  │  임베딩)      │   │ (PDF 이미지  │
                  └──────┬───────┘   │  분석)       │
                         │           └──────────────┘
                         │
                         ▼
                  ┌──────────────┐
                  │  ChromaDB    │
                  │ (벡터 저장소) │
                  └──────────────┘
```

## 설치 및 실행

### 필수 요구사항
- Python 3.12+
- Redis 서버
- Ollama (로컬 LLM 서버)
- FFmpeg (오디오 처리용, 선택사항)

### Ollama 설치 및 설정

1. **Ollama 설치**
   ```bash
   # Linux/Mac
   curl -fsSL https://ollama.com/install.sh | sh
   
   # 또는 공식 사이트에서 설치: https://ollama.com
   ```

2. **bakllava 모델 다운로드**
   ```bash
   ollama pull bakllava
   ```

3. **Ollama 서버 실행**
   ```bash
   ollama serve
   ```
   - 기본적으로 `http://localhost:11434`에서 실행됩니다
   - GPU가 있으면 자동으로 사용합니다

### 환경 변수 설정
`.env` 파일에 다음 변수를 설정해야 합니다:
- `SECRET_KEY`: Django 시크릿 키
- `GEMINI_API_KEY`: Google Gemini API 키
- `OLLAMA_BASE_URL`: Ollama 서버 URL (기본값: `http://localhost:11434`)
- `OLLAMA_MODEL`: 사용할 모델명 (기본값: `bakllava`)
- `OLLAMA_BATCH_SIZE`: PDF 처리 배치 크기 (기본값: `4`)
- `OLLAMA_TIMEOUT`: Ollama 요청 타임아웃(초) (기본값: `30`)
- `OLLAMA_MAX_RETRIES`: Ollama 요청 최대 재시도 횟수 (기본값: `2`)

### 실행 방법
1. 의존성 설치: `pip install -r requirements.txt`
2. 데이터베이스 마이그레이션: `python manage.py migrate`
3. Redis 서버 실행: `redis-server`
4. Ollama 서버 실행: `ollama serve` (별도 터미널)
5. Celery 워커 실행: `celery -A config worker -l info` (별도 터미널)
6. Django 서버 실행: `python manage.py runserver`

## 주요 특징

- **병렬 처리 최적화**: 독립적인 작업들을 동시에 실행하여 전체 처리 시간 단축
  - 병렬 그룹 1: STT + PDF 파싱 동시 실행
  - 병렬 그룹 2: 요약 + 임베딩 동시 실행
- **비동기 처리**: Celery를 사용하여 파일 업로드 후 즉시 응답, 백그라운드에서 처리
- **실시간 진행 상황**: 처리 중 페이지에서 4단계별 진행률 및 소요 시간 표시 (병렬 구조 반영)
- **하이브리드 PDF 처리**: PyMuPDF로 정확한 텍스트 추출 + Ollama로 이미지 분석
- **Ollama 타임아웃 및 재시도**: PDF 이미지 분석 시 타임아웃 및 자동 재시도로 안정성 향상
- **로컬 LLM 활용**: Ollama를 사용하여 PDF 이미지 분석 시 API 비용 절감 및 처리 속도 향상
- **단계별 소요 시간 추적**: 각 처리 단계의 소요 시간을 실시간으로 표시하여 성능 모니터링
- **예상 소요 시간**: 병렬 처리 구조를 반영한 정확한 처리 시간 예측
- **의미 기반 검색**: 벡터 유사도를 활용한 정확한 문서 검색
- **자동 매핑**: AI가 요약 내용과 PDF 페이지를 자동으로 연결
- **반응형 UI**: 모바일과 데스크톱 모두에서 최적화된 사용자 경험

## 테스트

PDF 처리 기능을 테스트하려면 `test_pdf_processing/` 디렉토리의 스크립트를 사용할 수 있습니다:

```bash
# bakllava 모델로 PDF 처리 테스트
python test_pdf_processing/test_bakllava_pdf.py
```

자세한 내용은 `test_pdf_processing/README.md`를 참조하세요.
