# ReLec - 강의 음성 및 PDF 자동 처리 시스템

</br>

## 📝 프로젝트 개요
온라인 교육 환경이 확대되면서 학생들은 영상·오디오 기반의 강의와 PDF 중심의 강의자료를 함께 활용해야 합니다. 그러나 이 두 자료가 서로 연동되지 않아, 학습자는 강의의 설명이 교재의 어느 부분인지 직접 찾아야 하는 비효율을 겪고 있습니다. 또한, 긴 강의 시간과 방대한 자료 속에서 필요한 내용을 신속하게 찾거나 구조적으로 복습하기 어려운 문제가 지속되고 있습니다. 저희는 이러한 문제를 해결하기 위해 ReLec을 기획하여 강의 녹음, 요약, PDF 자료가 유기적으로 연결된 지능형 학습 지원 시스템을 구축하였습니다.

</br>

**💡 강의 음성과 PDF 자료의 단절로 인한 학습 비효율**

- 음성 강의와 PDF 자료가 독립적으로 제공되어, 학생이 직접 설명과 교재 페이지를 매칭하며 탐색해야 하는 시간을 획기적으로 단축합니다.
- 강의의 소주제 요약과 가장 연관성 높은 PDF 페이지를 자동으로 매핑하여, 학습자가 문맥에 맞춰 자료를 즉시 확인할 수 있도록 지원합니다.

**💡 긴 강의 콘텐츠의 탐색 및 구조적 복습의 어려움**

- 단순 텍스트 변환(STT)을 넘어, 강의 흐름에 맞춘 '소주제-요약-원본 구간'의 구조화된 정보를 제공하여 긴 강의도 빠르게 파악할 수 있습니다.
- 타임스탬프가 포함된 스크립트와 요약 정보를 통해, 원하는 구간으로 즉시 이동하여 효율적인 반복 학습이 가능합니다.

**💡 단순 키워드 검색의 한계와 맥락 파악 부족**

- 기존의 단순 키워드 검색을 넘어, 의미 기반 벡터 검색 엔진을 통해 강의 내용의 맥락을 반영한 정교한 탐색을 지원합니다.
- RAG(검색 증강 생성) 기술을 활용하여, 학습자가 질문하면 강의 자료(PDF 및 스크립트) 내에서 정확한 근거를 찾아 문맥에 맞는 답변을 제공합니다.

</br>

## 📝 프로젝트 소개
강의 음성·영상·PDF를 통합 분석하여 자동화된 학습 환경을 제공하는 AI 학습 비서

> ### 🔷 1. 하이브리드 AI 기반 자동 처리 파이프라인

* **Cloud AI(Gemini)와 Local LLM(Ollama/BakLLaVA)**을 결합하여 고속 음성 전사 및 이미지 분석을 수행, 성능과 비용 효율을 동시에 확보했습니다.
* 강의 업로드 즉시 STT 처리, PDF 파싱, 구조화 요약, 의미 매핑의 4단계 파이프라인이 병렬적으로 실행되어 대기 시간을 최소화합니다.

> ### 🔷 2. 구조화된 요약 및 PDF 의미 매핑 (Semantic Mapping)

* 전체 강의 스크립트를 소주제 단위로 요약하고, 해당 내용과 가장 유사도가 높은 PDF 페이지를 자동으로 연결해줍니다.
* 학습자는 요약된 내용을 보며 관련된 교재 페이지를 바로 참고할 수 있어 학습 흐름이 끊기지 않습니다.

> ### 🔷 3. 통합 학습 페이지 (Viewer & Script)

* **PDF 뷰어, 음성 스크립트, 소주제 요약**을 한 화면에서 통합 제공합니다.
* 스크립트의 타임스탬프를 클릭하면 해당 시점의 오디오가 재생되며, PDF도 페이지 단위로 자유롭게 탐색 가능합니다.

> ### 🔷 4. RAG 기반 질의응답 (AI Tutor)

* 사용자가 강의 내용에 대해 질문하면, 시스템이 PDF와 스크립트 임베딩을 검색하여 근거 기반의 정확한 답변을 생성합니다.
* 강의 소유자만 질문이 가능하도록 설계하여 데이터 관리의 일관성과 보안을 유지합니다.
  
> ### 🔷 5. 시스템 안정성 및 결함 내성 (Fault Tolerance)

* 지수 백오프(Exponential Backoff) 기반의 재시도 로직과 JSON 자동 복구 기능을 적용하여 API 오류나 데이터 파손 시에도 중단 없이 처리를 완수합니다.
* Celery 비동기 큐를 활용하여 무거운 연산 작업을 백그라운드에서 안정적으로 처리합니다.

> ### 🔷 6. 예상 소요 시간(ETR) 및 관리자 대시보드

* 강의 길이와 페이지 수를 기반으로 처리 완료까지의 **예상 소요 시간(ETR)**을 계산하여 사용자에게 안내합니다.
* 관리자 대시보드를 통해 파이프라인 단계별 처리 속도와 시스템 상태를 실시간으로 모니터링할 수 있습니다.

</br>

------

## 기술 스택

### 백엔드
- **Django 5.2.7**: 웹 프레임워크
- **Celery**: 비동기 작업 처리
- **Redis**: 메시지 브로커 및 결과 저장소
- **SQLite**: 관계형 데이터베이스

### AI/ML 서비스
- **Google Gemini API**: 
  - STT (Speech-to-Text): 오디오를 텍스트로 변환
  - 텍스트 요약: 강의 스크립트를 소주제별로 요약
  - 텍스트 임베딩: 의미 기반 검색을 위한 벡터 생성
- **Ollama (로컬 LLM)**:
  - PDF 이미지 분석: bakllava 멀티모달 모델을 사용하여 PDF 내 이미지, 다이어그램, 차트 분석
  - 로컬 실행으로 API 비용 절감 및 처리 속도 향상

### 벡터 데이터베이스
- **ChromaDB**: PDF와 스크립트의 임베딩 벡터를 저장하여 의미 기반 검색 지원

### 프론트엔드
- **Bootstrap 5**: 반응형 UI 프레임워크
- **PDF.js**: PDF 파일 렌더링
- **Marked.js**: 마크다운 렌더링 (AI 응답 표시용)

### 유틸리티
- **PyMuPDF (fitz)**: PDF 파싱 및 텍스트 추출
- **Ollama**: 로컬 멀티모달 LLM 실행 (bakllava 모델)
- **mutagen/ffprobe/pydub**: 오디오 파일 길이 측정
- **yt-dlp**: YouTube 동영상에서 오디오만 다운로드

## 주요 기능

### 1. 사용자 인증
- 회원가입 및 로그인
- 사용자별 강의 데이터 관리

### 2. 강의 파일 업로드
- **오디오 파일 업로드** 또는 **YouTube URL 입력** (음성 강의)
  - 파일 업로드: MP3, M4A, WAV 형식 지원
  - YouTube URL: yt-dlp를 사용하여 오디오만 자동 다운로드 (10분 타임아웃, 약 1분 소요 안내 메시지 표시)
- PDF 파일 업로드 (강의 자료)
- 예상 소요 시간(ETR) 자동 계산 및 표시

### 3. 자동 처리 파이프라인 (병렬 처리 최적화)
강의 파일이 업로드되면 다음 4단계가 **병렬 처리**를 통해 자동으로 실행됩니다:

#### 병렬 그룹 1: STT 처리 + PDF 파싱 (동시 실행)
- **STT 처리**: 오디오 파일을 Gemini API를 통해 텍스트로 변환 (타임스탬프 포함, 500초 타임아웃)
  - **API 재시도 로직**: 503 ServiceUnavailable, 서버 에러, Rate Limit 발생 시 지수 백오프로 자동 재시도 (최대 10초 대기)
  - 파일 업로드와 실제 전사 시간을 별도로 측정하여 성능 모니터링
- **PDF 파싱**: 
  - **하이브리드 방식**: PyMuPDF로 페이지 텍스트를 정확하고 빠르게 추출
  - 페이지에서 이미지 객체 추출
  - 각 이미지를 Ollama bakllava 모델로 분석 (영어 설명, 강제 타임아웃 및 재시도 포함)
    - **강제 타임아웃**: threading을 사용하여 Ollama API 호출에 강제 타임아웃 적용 (무한 대기 방지)
    - **페이지 전체 타임아웃**: 페이지 처리 시간이 타임아웃을 초과하면 남은 이미지 분석을 건너뛰고 다음 페이지로 진행
    - **즉시 재시도**: 타임아웃 발생 시 짧은 대기(0.5초) 후 즉시 재시도
    - **배치 처리 타임아웃**: 각 future의 시작 시간을 추적하여 개별 타임아웃 체크, 타임아웃된 future는 즉시 취소
  - 텍스트와 이미지 설명을 결합하여 완전한 페이지 내용 생성
- 두 작업이 **동시에 실행**되어 전체 처리 시간 단축
- 각 작업 완료 시 소요 시간 표시

#### 병렬 그룹 2: 요약 생성 + 임베딩 (지연 시작으로 API 병목 방지)
- **스크립트 요약 생성**: 전체 스크립트를 Gemini API로 분석하여 소주제별로 구조화된 요약 생성 (500초 타임아웃)
  - 각 소주제에 대한 핵심 내용, 원본 구간, 타임스탬프 정보 포함
  - **JSON 오류 처리 및 재시도**: 
    - JSON 응답 추출: 마크다운 코드 블록, 앞뒤 설명 텍스트 자동 제거
    - JSON 복구 시도: 불완전한 JSON(닫는 중괄호 누락 등) 자동 복구
    - JSON 구조 검증: `summary_list` 키 존재 확인, 리스트 타입 검증, 필수 필드 확인
    - 재시도 로직: 최대 3회 재시도, 지수 백오프 대기 (2초, 4초, 최대 10초)
    - 필드 누락 처리: 필수 필드 누락 시 기본값 자동 설정
  - **API 재시도 로직**: 503 ServiceUnavailable, 서버 에러, Rate Limit 발생 시 지수 백오프로 자동 재시도 (최대 15초 대기)
- **임베딩 및 벡터 DB 저장**:
  - 요약 시작 후 10초 지연하여 시작 (API 호출 병목 방지)
  - PDF 페이지와 스크립트를 청크 단위로 분할
  - **배치 임베딩**: 모든 요약 항목을 한 번의 API 호출로 배치 처리하여 API 호출 최소화
  - 각 청크를 Gemini Embedding API로 벡터화
  - ChromaDB에 저장하여 의미 기반 검색 가능하도록 구성
- 요약이 먼저 시작되고, 10초 후 임베딩이 시작되어 API 호출 충돌 최소화
- 각 작업 완료 시 소요 시간 표시 (임베딩의 10초 지연 시간은 통계에서 제외)

#### 순차 처리 1: 의미 기반 매핑
- 요약의 각 소주제를 PDF의 해당 페이지와 의미적으로 매핑
- 벡터 유사도 검색을 통해 가장 관련성 높은 PDF 페이지 자동 연결
- 소요 시간 표시

#### 순차 처리 2: 데이터 저장
- 처리된 모든 데이터를 데이터베이스에 저장
- PdfChunk 및 Mapping 모델에 저장
- 사용자가 학습 페이지에서 접근 가능하도록 준비
- 소요 시간 표시

### 4. 학습 페이지
- **접근 제어**: 로그인한 모든 사용자가 강의를 볼 수 있도록 공유 기능 지원
  - 로그인하지 않은 사용자는 로그인 페이지로 리다이렉트되며, 로그인 후 원래 접속하려던 페이지로 자동 이동
- **공유 기능**: 공유하기 버튼을 통해 현재 페이지 URL을 클립보드에 복사
- **PDF 뷰어**: 강의 자료를 페이지별로 표시
- **음성 스크립트**: 타임스탬프가 포함된 전체 스크립트 표시
- **소주제별 요약**: 아코디언 형태로 요약 내용 표시 (PDF 페이지 번호 포함)
- **RAG 챗봇**: 강의 내용에 대한 질문에 AI가 답변 (벡터 검색 기반)
  - 소유자가 아닌 사용자의 경우 입력 필드와 전송 버튼이 비활성화되며 안내 메시지 표시
- **요약/스크립트 파일 다운로드**: 소주제별 요약본과 전체 스크립트를 PDF 파일로 다운로드 (한글 파일명 지원)
  - **요약 다운로드**: 소주제별 요약, 타임스탬프, PDF 페이지 매핑 정보를 Markdown 형식으로 변환 후 PDF 생성
  - **스크립트 다운로드**: 타임스탬프가 포함된 전체 스크립트를 Markdown 형식으로 변환 후 PDF 생성

### 5. 관리자 대시보드
- **접근 권한**: `is_staff` 플래그가 있는 사용자만 접근 가능
- **처리 통계**: ProcessingStats의 실시간 통계 표시
  - STT 평균 (초/분)
  - PDF 파싱 평균 (초/페이지)
  - 임베딩 평균 (초/페이지)
  - 요약 평균 (초/분)
  - 마지막 업데이트 시간
- **데이터베이스 정보**: 각 모델의 테이블 정보 표시
  - 실제 사용 중인 컬럼만 필터링하여 표시
  - 각 테이블의 튜플 수 표시

### 6. 예상 소요 시간(ETR) 시스템
- 업로드 시 오디오 길이와 PDF 페이지 수를 기반으로 처리 시간 예측
- **병렬 처리 구조 반영**: 각 병렬 그룹에서 가장 긴 작업 시간을 사용하여 정확한 예측
  - 병렬 그룹 1: max(오디오_길이_분 × STT 평균, PDF_페이지_수 × PDF 파싱 평균)
  - 병렬 그룹 2: max(오디오_길이_분 × 요약 평균, PDF_페이지_수 × 임베딩 평균)
- 과거 처리 통계를 학습하여 점진적으로 정확도 향상
- 이동 평균 방식으로 통계 업데이트 (기존 50%, 새 50%)
- 개별 통계 추적: STT, PDF 파싱, 임베딩, 요약 각각의 평균 시간을 별도로 관리

## 애플리케이션 워크플로우

### 1. 사용자 인증 흐름
```
사용자 접속 → 로그인/회원가입 → 인증 완료 → 업로드 페이지

공유 링크 접속 시:
공유 링크 접속 → 로그인 페이지 (next 파라미터 포함) → 로그인 → 원래 접속하려던 강의 페이지
```

### 2. 파일 업로드 및 처리 흐름
```
파일 업로드 또는 YouTube URL 입력 (오디오 + PDF)
    ↓
데이터베이스에 강의 정보 저장
    │                ↓
    │       [YouTube URL인 경우] yt-dlp로 오디오 다운로드 (10분 타임아웃)
    ↓                ↓
ETR 계산 태스크 시작 (비동기, 빠른 계산)
    ↓
처리 중 페이지로 즉시 리다이렉트
    ↓
Celery 백그라운드 작업 시작
    ├─ 병렬 그룹 1 (동시 실행):
    │   ├─ STT 처리 (오디오 → 텍스트)
    │   └─ PDF 파싱 및 텍스트 추출 (PyMuPDF + Ollama 이미지 분석)
    ├─ 병렬 그룹 2 (동시 실행):
    │   ├─ 요약 생성 (소주제별 구조화)
    │   └─ 임베딩 생성 및 ChromaDB 저장
    ├─ 순차 처리:
    │   ├─ 의미 기반 매핑 (요약 ↔ PDF 페이지)
    │   └─ 데이터 저장
    └─ 처리 통계 업데이트 (ETR 예측 정확도 향상)
    ↓
처리 완료 
    ↓
학습 페이지로 자동 이동
```

### 3. 학습 페이지 사용 흐름
```
학습 페이지 접속 (로그인 필수)
    ├─ 공유하기: 현재 페이지 URL 복사하여 다른 사용자와 공유
    ├─ PDF 뷰어: 강의 자료 확인
    ├─ 스크립트: 타임스탬프별 음성 내용 확인
    ├─ 요약본: 소주제별 핵심 내용 확인 (PDF 페이지 링크 포함)
    │   └─ 요약/스크립트 파일 다운로드 (PDF 형식, Markdown 변환)
    └─ RAG 챗봇: 강의 내용에 대한 질문 및 답변 (소유자만 사용 가능)
        └─ 소유자가 아닌 경우: 입력 필드 비활성화 및 안내 메시지 표시
```

### 4. PDF 처리 방식 (하이브리드)
```
PDF 페이지 처리
    ↓
PyMuPDF로 텍스트 추출 (정확하고 빠름)
    ↓
페이지에서 이미지 객체 추출
    ↓
각 이미지를 Ollama bakllava로 분석
    ├─ 이미지 내용 설명 (영어)
    ├─ 다이어그램, 차트 분석
    └─ 수식 및 시각적 요소 설명
    ↓
텍스트 + 이미지 설명 결합
    ↓
최종 페이지 내용 생성
```

### 5. RAG 챗봇 동작 흐름
```
사용자 질문 입력
    ↓
질문을 임베딩 벡터로 변환
    ↓
ChromaDB에서 유사한 문서 검색 (PDF 페이지 또는 스크립트)
    ↓
검색된 컨텍스트와 질문을 Gemini에 전달
    ↓
AI가 컨텍스트 기반 답변 생성
    ↓
사용자에게 답변 표시 (마크다운 렌더링)
```

## 데이터 모델 구조

### 핵심 모델
- **CustomUser**: 사용자 계정 정보
- **Lecture**: 강의 메타데이터 및 처리 상태
  - `status`: 처리 상태 (`processing`: 처리 중, `completed`: 완료, `failed`: 실패)
  - `current_step`: 현재 처리 단계 (0, 1, 3, 5, 6 - 병렬 구조 반영)
  - `step_times`: 단계별 소요 시간 (JSON 형식)
  - `estimated_time_sec`: 예상 소요 시간(초, 병렬 구조 기반 계산)
  - `youtube_url`: YouTube URL (파일 업로드 대신 사용 가능)
  - `audio_file`: 오디오 파일 경로 (파일 업로드 또는 YouTube 다운로드 후)
  - `created_at`: 강의 생성 일시 (오래된 작업 감지에 사용)
- **PdfChunk**: PDF 페이지별 텍스트 내용 (텍스트 + 이미지 설명 포함)
- **Mapping**: 요약 소주제와 PDF 페이지의 의미 기반 매핑
- **ProcessingStats**: 처리 속도 통계 (ETR 예측용)
  - `audio_stt_avg_sec_per_min`: STT 평균 시간 (초/분)
  - `pdf_parsing_avg_sec_per_page`: PDF 파싱 평균 시간 (초/페이지)
  - `embedding_avg_sec_per_page`: 임베딩 평균 시간 (초/페이지)
  - `summary_avg_sec_per_min`: 요약 평균 시간 (초/분)

## 시스템 아키텍처

```
┌─────────────┐
│   사용자     │
└──────┬──────┘
       │
       ▼
┌─────────────────┐
│  Django 서버    │
│  (웹 인터페이스) │
└──────┬──────────┘
       │
       ├─────────────────┐
       │                 │
       ▼                 ▼
┌─────────────┐   ┌──────────────┐
│   SQLite    │   │   Celery     │
│  (메타데이터)│   │  (비동기 작업)│
└─────────────┘   └──────┬───────┘
                         │
                         ▼
                  ┌──────────────┐
                  │    Redis     │
                  │ (작업 큐)    │
                  └──────────────┘
                         │
                         ├─────────────────┐
                         │                 │
                         ▼                 ▼
                  ┌──────────────┐   ┌──────────────┐
                  │  Gemini API  │   │   Ollama     │
                  │ (STT/요약/   │   │ (로컬 LLM)   │
                  │  임베딩)      │   │ (PDF 이미지  │
                  └──────┬───────┘   │  분석)       │
                         │           └──────────────┘
                         │
                         ▼
                  ┌──────────────┐
                  │  ChromaDB    │
                  │ (벡터 저장소) │
                  └──────────────┘
```

## 설치 및 실행

### 필수 요구사항

#### 시스템 요구사항
- **Python 3.12+**: Django 5.2.7 및 모든 Python 패키지 실행을 위해 필요
- **Redis 서버**: Celery 브로커 및 결과 백엔드로 사용
- **Ollama**: 로컬 LLM 서버 (PDF 이미지 분석용)
- **FFmpeg**: 오디오 파일 처리용 (pydub가 필요로 함)

#### Python 패키지
다음 패키지들이 `requirements.txt`에 포함되어 있으며, `pip install -r requirements.txt`로 자동 설치됩니다:
- Django 5.2.7
- django-environ 0.11.2
- google-generativeai (Gemini API)
- PyMuPDF (PDF 텍스트 추출)
- chromadb (벡터 데이터베이스)
- celery (비동기 작업 처리)
- redis (Celery 브로커)
- mutagen, pydub (오디오 처리)
- ollama (로컬 LLM 클라이언트)
- yt-dlp (YouTube 오디오 다운로드)
- tqdm (진행률 표시)
- reportlab (PDF 생성)
- markdown (Markdown to HTML 변환)

### 요구사항 설치 방법

#### 1. Python 설치
```bash
# Python 3.12 이상이 설치되어 있는지 확인
python3 --version

# 설치되어 있지 않은 경우
# Ubuntu/Debian
sudo apt update
sudo apt install python3.12 python3.12-venv python3-pip

# macOS (Homebrew 사용)
brew install python@3.12
```

#### 2. Redis 서버 설치 및 실행
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install redis-server
sudo systemctl start redis-server
sudo systemctl enable redis-server  # 부팅 시 자동 시작

# macOS (Homebrew 사용)
brew install redis
brew services start redis

# 설치 확인
redis-cli ping  # PONG 응답이 나오면 정상
```

#### 3. FFmpeg 설치
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install ffmpeg

# macOS (Homebrew 사용)
brew install ffmpeg

# 설치 확인
ffmpeg -version
```

#### 4. Ollama 설치 및 설정

1. **Ollama 설치**
   ```bash
   # Linux/Mac
   curl -fsSL https://ollama.com/install.sh | sh
   
   # 또는 공식 사이트에서 설치: https://ollama.com
   ```

2. **bakllava 모델 다운로드**
   ```bash
   ollama pull bakllava
   ```

3. **Ollama 서버 실행**
   ```bash
   ollama serve
   ```
   - 기본적으로 `http://localhost:11434`에서 실행됩니다
   - GPU가 있으면 자동으로 사용합니다

#### 5. Python 패키지 설치
```bash
# 가상 환경 생성 (권장)
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# 또는
# venv\Scripts\activate  # Windows

# 프로젝트 의존성 설치
pip install -r requirements.txt
```

### 환경 변수 설정
프로젝트 루트 디렉토리에 `.env` 파일을 생성하고 다음 변수를 설정해야 합니다:

#### 필수 환경 변수
- `SECRET_KEY`: Django 시크릿 키
- `GEMINI_API_KEY`: Google Gemini API 키

#### 선택적 환경 변수
- `OLLAMA_BASE_URL`: Ollama 서버 URL
- `OLLAMA_MODEL`: 사용할 모델명
- `OLLAMA_BATCH_SIZE`: PDF 처리 배치 크기
- `OLLAMA_TIMEOUT`: Ollama 요청 타임아웃(초)
- `OLLAMA_MAX_RETRIES`: Ollama 요청 최대 재시도 횟수

#### .env 파일 예시
```env
SECRET_KEY=your-django-secret-key-here
GEMINI_API_KEY=your-gemini-api-key-here
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=bakllava
OLLAMA_BATCH_SIZE=4
OLLAMA_TIMEOUT=30
OLLAMA_MAX_RETRIES=2
```

### 관리자 계정 생성
관리자 대시보드에 접근하려면 `is_staff` 플래그가 있는 계정이 필요합니다:
```bash
python manage.py create_admin
```
기본 관리자 계정 (ID: `admin`, 비밀번호: `000000`)이 생성되거나 업데이트됩니다.

기본 ID/PW 수정은 lecture/management/commands/create_admin.py에서 가능합니다.

### ETR 시스템 초기화
명령어를 통해 통계값을 기본값으로 초기화합니다.
```bash
python manage.py init_processing_stats
```

### 실행 방법
1. 의존성 설치: `pip install -r requirements.txt`
2. 데이터베이스 마이그레이션: `python manage.py migrate`
3. Redis 서버 실행: `redis-server`
4. Ollama 서버 실행: `ollama serve` (별도 터미널)
5. Celery 워커 실행: `celery -A config worker -l info` (별도 터미널)
6. Django 서버 실행: `python manage.py runserver`

### 작업 실패 처리 및 복구
시스템은 작업 실패를 자동으로 감지하고 처리합니다:

- **자동 실패 처리**: Celery 작업이 실패하거나 예외가 발생하면 자동으로 강의 상태를 `failed`로 업데이트
- **작업 안정성**: Celery 설정으로 작업 손실 방지 (`task_acks_late`, `task_reject_on_worker_lost`)
- **자동 오래된 작업 감지 및 실패 처리**: **Celery 워커가 시작될 때 자동으로** 다음 작업을 수행합니다:
  1. **오래된 작업 실패 처리**: 18분 이상 지난 "처리 중" 작업을 감지하고 실패로 표시
  2. 멈춘 작업은 재시작하지 않고 실패 상태로 변경하여 중복 처리나 무한 루프를 방지
- **수동 오래된 작업 감지**: 관리 명령어를 통해 수동으로 오래된 작업을 감지할 수 있음

#### 자동 감지 및 실패 처리
Celery 워커를 시작하면 (`celery -A config worker -l info`) 자동으로 다음 작업을 수행합니다:
1. 18분 이상 지난 "처리 중" 작업을 실패로 표시

별도의 설정이나 명령어 실행이 필요 없습니다. 멈춘 작업은 재시작하지 않고 실패 상태로 변경되어 데이터 일관성을 유지합니다.

#### 수동 감지 명령어
필요한 경우 수동으로도 실행할 수 있습니다:
```bash
# 기본값(18분) 이상 지난 "처리 중" 작업을 실패로 표시
python manage.py check_stuck_tasks

# 지정된 시간 이상 지난 작업만 실패로 표시
python manage.py check_stuck_tasks --minutes 10

# 실제로 변경하지 않고 확인만 (dry-run)
python manage.py check_stuck_tasks --dry-run

# Celery에 남은 쿼리 모두 종류
celery -A config purge -f
```

이 명령어를 주기적으로 실행하거나 cron job으로 설정하여 추가로 오래된 작업을 감지할 수 있습니다.

## 주요 특징

- **병렬 처리 최적화**: 독립적인 작업들을 동시에 실행하여 전체 처리 시간 단축
  - 병렬 그룹 1: STT + PDF 파싱 동시 실행
  - 병렬 그룹 2: 요약 + 임베딩 (임베딩은 요약 시작 후 10초 지연 시작하여 API 병목 방지)
- **API 호출 최적화**: 
  - 배치 임베딩 처리로 API 호출 횟수 최소화
  - 임베딩 지연 시작으로 요약 API와의 충돌 방지
- **API 재시도 로직**: 
  - STT 및 요약 생성 시 503 ServiceUnavailable, 서버 에러, Rate Limit 발생 시 지수 백오프로 자동 재시도
  - STT: 최대 10초 대기
  - 요약: 최대 15초 대기 (더 긴 처리 시간 고려)
- **비동기 처리**: Celery를 사용하여 파일 업로드 후 즉시 응답, 백그라운드에서 처리
- **작업 실패 처리**: 작업 실패 시 자동으로 상태를 `failed`로 업데이트하고, 오래된 "처리 중" 작업을 감지하여 실패로 표시하는 기능 제공
- **작업 안정성**: Celery 설정으로 작업 손실 방지 및 워커 중단 시 작업 재시도 지원
- **실시간 진행 상황**: 처리 중 페이지에서 4단계별 진행률 및 소요 시간 표시 (병렬 구조 반영)
- **하이브리드 PDF 처리**: PyMuPDF로 정확한 텍스트 추출 + Ollama로 이미지 분석
- **Ollama 타임아웃 및 재시도**: PDF 이미지 분석 시 강제 타임아웃 및 자동 재시도로 안정성 향상
  - **강제 타임아웃**: threading을 사용하여 Ollama API 호출에 강제 타임아웃 적용 (무한 대기 방지)
  - **페이지 전체 타임아웃**: 페이지 처리 시간이 타임아웃을 초과하면 남은 이미지 분석을 건너뛰고 다음 페이지로 진행
  - **즉시 재시도**: 타임아웃 발생 시 짧은 대기(0.5초) 후 즉시 재시도
  - **배치 처리 타임아웃**: 각 future의 시작 시간을 추적하여 개별 타임아웃 체크, 타임아웃된 future는 즉시 취소
  - **재시도 루프 내 타임아웃 체크**: 재시도 중에도 페이지 전체 타임아웃을 체크하여 무한 대기 방지
- **로컬 LLM 활용**: Ollama를 사용하여 PDF 이미지 분석 시 API 비용 절감 및 처리 속도 향상
- **YouTube URL 지원**: 파일 업로드 대신 YouTube URL을 입력하여 오디오 자동 다운로드 (10분 타임아웃)
- **Gemini API 타임아웃**: STT 및 요약 생성 시 500초 타임아웃 설정으로 무한 대기 방지
- **JSON 오류 처리 및 재시도**: 요약 생성 시 JSON 형식 오류를 자동으로 처리
- **단계별 소요 시간 추적**: 각 처리 단계의 소요 시간을 실시간으로 표시하여 성능 모니터링
- **예상 소요 시간**: 병렬 처리 구조를 반영한 정확한 처리 시간 예측
- **의미 기반 검색**: 벡터 유사도를 활용한 정확한 문서 검색
- **자동 매핑**: AI가 요약 내용과 PDF 페이지를 자동으로 연결
- **강의 공유 기능**: 
  - 공유하기 버튼을 통해 URL 복사 및 공유
  - 로그인하지 않은 사용자는 로그인 후 원래 페이지로 자동 리다이렉트
  - RAG 기능은 강의 소유자만 사용 가능 (권한 제어)
- **관리자 대시보드**: 
  - 권한 기반 접근 제어
  - ProcessingStats 실시간 통계 모니터링
  - 데이터베이스 테이블 정보 조회
- **PDF 다운로드 기능**: 소주제별 요약본과 스크립트를 Markdown 형식으로 PDF 파일로 다운로드
- **타임존 설정**: 한국 표준시(KST, Asia/Seoul) 사용
- **반응형 UI**: 모바일과 데스크톱 모두에서 최적화된 사용자 경험
