# LectureAI - 강의 음성 및 PDF 자동 처리 시스템

강의 오디오 파일과 PDF 자료를 업로드하면, AI가 자동으로 음성을 텍스트로 변환하고, 강의 내용을 요약하며, PDF와 음성 스크립트를 의미 기반으로 매핑하는 지능형 학습 지원 시스템입니다.

## 기술 스택

### 백엔드
- **Django 5.2.7**: 웹 프레임워크
- **Celery**: 비동기 작업 처리
- **Redis**: 메시지 브로커 및 결과 저장소
- **SQLite**: 관계형 데이터베이스

### AI/ML 서비스
- **Google Gemini API**: 
  - STT (Speech-to-Text): 오디오를 텍스트로 변환
  - 텍스트 요약: 강의 스크립트를 소주제별로 요약 (JSON 오류 처리 및 재시도 로직 포함)
  - 텍스트 임베딩: 의미 기반 검색을 위한 벡터 생성
- **Ollama (로컬 LLM)**:
  - PDF 이미지 분석: bakllava 멀티모달 모델을 사용하여 PDF 내 이미지, 다이어그램, 차트 분석
  - 로컬 실행으로 API 비용 절감 및 처리 속도 향상

### 벡터 데이터베이스
- **ChromaDB**: PDF와 스크립트의 임베딩 벡터를 저장하여 의미 기반 검색 지원

### 프론트엔드
- **Bootstrap 5**: 반응형 UI 프레임워크
- **PDF.js**: PDF 파일 렌더링
- **Marked.js**: 마크다운 렌더링 (AI 응답 표시용)

### 유틸리티
- **PyMuPDF (fitz)**: PDF 파싱 및 텍스트 추출
- **Ollama**: 로컬 멀티모달 LLM 실행 (bakllava 모델)
- **mutagen/ffprobe/pydub**: 오디오 파일 길이 측정
- **yt-dlp**: YouTube 동영상에서 오디오만 다운로드

## 주요 기능

### 1. 사용자 인증
- 회원가입 및 로그인
- 사용자별 강의 데이터 관리

### 2. 강의 파일 업로드
- **오디오 파일 업로드** 또는 **YouTube URL 입력** (음성 강의)
  - 파일 업로드: MP3, M4A, WAV 형식 지원
  - YouTube URL: yt-dlp를 사용하여 오디오만 자동 다운로드 (10분 타임아웃, 약 1분 소요 안내 메시지 표시)
- PDF 파일 업로드 (강의 자료)
- 예상 소요 시간(ETR) 자동 계산 및 표시

### 3. 자동 처리 파이프라인 (병렬 처리 최적화)
강의 파일이 업로드되면 다음 4단계가 **병렬 처리**를 통해 자동으로 실행됩니다:

#### 병렬 그룹 1: STT 처리 + PDF 파싱 (동시 실행)
- **STT 처리**: 오디오 파일을 Gemini API를 통해 텍스트로 변환 (타임스탬프 포함, 500초 타임아웃)
  - **API 재시도 로직**: 503 ServiceUnavailable, 서버 에러, Rate Limit 발생 시 지수 백오프로 자동 재시도 (최대 10초 대기)
  - 파일 업로드와 실제 전사 시간을 별도로 측정하여 성능 모니터링
- **PDF 파싱**: 
  - **하이브리드 방식**: PyMuPDF로 페이지 텍스트를 정확하고 빠르게 추출
  - 페이지에서 이미지 객체 추출
  - 각 이미지를 Ollama bakllava 모델로 분석 (영어 설명, 강제 타임아웃 및 재시도 포함)
    - **강제 타임아웃**: threading을 사용하여 Ollama API 호출에 강제 타임아웃 적용 (무한 대기 방지)
    - **페이지 전체 타임아웃**: 페이지 처리 시간이 타임아웃을 초과하면 남은 이미지 분석을 건너뛰고 다음 페이지로 진행
    - **즉시 재시도**: 타임아웃 발생 시 짧은 대기(0.5초) 후 즉시 재시도
    - **배치 처리 타임아웃**: 각 future의 시작 시간을 추적하여 개별 타임아웃 체크, 타임아웃된 future는 즉시 취소
  - 텍스트와 이미지 설명을 결합하여 완전한 페이지 내용 생성
- 두 작업이 **동시에 실행**되어 전체 처리 시간 단축
- 각 작업 완료 시 소요 시간 표시

#### 병렬 그룹 2: 요약 생성 + 임베딩 (지연 시작으로 API 병목 방지)
- **스크립트 요약 생성**: 전체 스크립트를 Gemini API로 분석하여 소주제별로 구조화된 요약 생성 (500초 타임아웃)
  - 각 소주제에 대한 핵심 내용, 원본 구간, 타임스탬프 정보 포함
  - **JSON 오류 처리 및 재시도**: 
    - JSON 응답 추출: 마크다운 코드 블록, 앞뒤 설명 텍스트 자동 제거
    - JSON 복구 시도: 불완전한 JSON(닫는 중괄호 누락 등) 자동 복구
    - JSON 구조 검증: `summary_list` 키 존재 확인, 리스트 타입 검증, 필수 필드 확인
    - 재시도 로직: 최대 3회 재시도, 지수 백오프 대기 (2초, 4초, 최대 10초)
    - 필드 누락 처리: 필수 필드 누락 시 기본값 자동 설정
  - **API 재시도 로직**: 503 ServiceUnavailable, 서버 에러, Rate Limit 발생 시 지수 백오프로 자동 재시도 (최대 15초 대기)
- **임베딩 및 벡터 DB 저장**:
  - 요약 시작 후 10초 지연하여 시작 (API 호출 병목 방지)
  - PDF 페이지와 스크립트를 청크 단위로 분할
  - **배치 임베딩**: 모든 요약 항목을 한 번의 API 호출로 배치 처리하여 API 호출 최소화
  - 각 청크를 Gemini Embedding API로 벡터화
  - ChromaDB에 저장하여 의미 기반 검색 가능하도록 구성
- 요약이 먼저 시작되고, 10초 후 임베딩이 시작되어 API 호출 충돌 최소화
- 각 작업 완료 시 소요 시간 표시 (임베딩의 10초 지연 시간은 통계에서 제외)

#### 순차 처리 1: 의미 기반 매핑
- 요약의 각 소주제를 PDF의 해당 페이지와 의미적으로 매핑
- 벡터 유사도 검색을 통해 가장 관련성 높은 PDF 페이지 자동 연결
- 소요 시간 표시

#### 순차 처리 2: 데이터 저장
- 처리된 모든 데이터를 데이터베이스에 저장
- PdfChunk 및 Mapping 모델에 저장
- 사용자가 학습 페이지에서 접근 가능하도록 준비
- 소요 시간 표시

### 4. 학습 페이지
- **접근 제어**: 로그인한 모든 사용자가 강의를 볼 수 있도록 공유 기능 지원
  - 강의 소유자뿐만 아니라 다른 사용자도 URL을 통해 강의 페이지에 접근 가능
  - 로그인하지 않은 사용자는 로그인 페이지로 리다이렉트되며, 로그인 후 원래 접속하려던 페이지로 자동 이동
- **공유 기능**: 공유하기 버튼을 통해 현재 페이지 URL을 클립보드에 복사
  - 클릭 시 현재 페이지의 전체 URL이 클립보드에 복사됨
  - 복사 성공 시 시각적 피드백 제공
- **PDF 뷰어**: 강의 자료를 페이지별로 표시
- **음성 스크립트**: 타임스탬프가 포함된 전체 스크립트 표시
- **소주제별 요약**: 아코디언 형태로 요약 내용 표시 (PDF 페이지 번호 포함)
- **RAG 챗봇**: 강의 내용에 대한 질문에 AI가 답변 (벡터 검색 기반)
  - **권한 제어**: 강의 소유자만 RAG 질의응답 기능 사용 가능
  - 소유자가 아닌 사용자의 경우 입력 필드와 전송 버튼이 비활성화되며 안내 메시지 표시
- **요약 파일 다운로드**: 소주제별 요약본을 TXT 파일로 다운로드 (한글 파일명 지원)
  - 요약 다운로드: 소주제별 요약, 타임스탬프, PDF 페이지 매핑 정보 포함
  - 스크립트 다운로드: 타임스탬프가 포함된 전체 스크립트를 TXT 파일로 다운로드
  - JavaScript 기반 자동 다운로드: 클릭 시 페이지 이동 없이 바로 파일 다운로드

### 5. 관리자 대시보드
- **접근 권한**: `is_staff` 플래그가 있는 사용자만 접근 가능
- **처리 통계**: ProcessingStats의 실시간 통계 표시
  - STT 평균 (초/분)
  - PDF 파싱 평균 (초/페이지)
  - 임베딩 평균 (초/페이지)
  - 요약 평균 (초/분)
  - 마지막 업데이트 시간
- **데이터베이스 정보**: 각 모델의 테이블 정보 표시
  - 모델 이름 우선 표시 (예: CustomUser (auth_user))
  - 실제 사용 중인 컬럼만 필터링하여 표시
  - 각 테이블의 튜플 수 표시

### 6. 예상 소요 시간(ETR) 시스템
- 업로드 시 오디오 길이와 PDF 페이지 수를 기반으로 처리 시간 예측
- **병렬 처리 구조 반영**: 각 병렬 그룹에서 가장 긴 작업 시간을 사용하여 정확한 예측
  - 병렬 그룹 1: max(오디오_길이_분 × STT 평균, PDF_페이지_수 × PDF 파싱 평균)
  - 병렬 그룹 2: max(오디오_길이_분 × 요약 평균, PDF_페이지_수 × 임베딩 평균)
- 과거 처리 통계를 학습하여 점진적으로 정확도 향상
- 이동 평균 방식으로 통계 업데이트 (기존 50%, 새 50%)
- 개별 통계 추적: STT, PDF 파싱, 임베딩, 요약 각각의 평균 시간을 별도로 관리

## 애플리케이션 워크플로우

### 1. 사용자 인증 흐름
```
사용자 접속 → 로그인/회원가입 → 인증 완료 → 업로드 페이지

공유 링크 접속 시:
공유 링크 접속 → 로그인 페이지 (next 파라미터 포함) → 로그인 → 원래 접속하려던 강의 페이지
```

### 2. 파일 업로드 및 처리 흐름
```
파일 업로드 또는 YouTube URL 입력 (오디오 + PDF)
    ↓
데이터베이스에 강의 정보 저장
    ↓
[YouTube URL인 경우] yt-dlp로 오디오 다운로드 (10분 타임아웃)
    ↓
ETR 계산 태스크 시작 (비동기, 빠른 계산)
    ↓
처리 중 페이지로 즉시 리다이렉트
    ↓
Celery 백그라운드 작업 시작
    ├─ 병렬 그룹 1 (동시 실행):
    │   ├─ STT 처리 (오디오 → 텍스트)
    │   └─ PDF 파싱 및 텍스트 추출 (PyMuPDF + Ollama 이미지 분석)
    ├─ 병렬 그룹 2 (동시 실행):
    │   ├─ 요약 생성 (소주제별 구조화)
    │   └─ 임베딩 생성 및 ChromaDB 저장
    ├─ 순차 처리:
    │   ├─ 의미 기반 매핑 (요약 ↔ PDF 페이지)
    │   └─ 데이터 저장
    └─ 처리 통계 업데이트 (ETR 예측 정확도 향상)
    ↓
처리 완료 → 학습 페이지로 자동 이동
```

### 3. 학습 페이지 사용 흐름
```
학습 페이지 접속 (로그인 필수)
    ├─ 공유하기: 현재 페이지 URL 복사하여 다른 사용자와 공유
    ├─ PDF 뷰어: 강의 자료 확인
    ├─ 스크립트: 타임스탬프별 음성 내용 확인
    ├─ 요약본: 소주제별 핵심 내용 확인 (PDF 페이지 링크 포함)
    │   └─ 요약/스크립트 파일 다운로드 (TXT 형식)
    └─ RAG 챗봇: 강의 내용에 대한 질문 및 답변 (소유자만 사용 가능)
        └─ 소유자가 아닌 경우: 입력 필드 비활성화 및 안내 메시지 표시
```

### 4. PDF 처리 방식 (하이브리드)
```
PDF 페이지 처리
    ↓
PyMuPDF로 텍스트 추출 (정확하고 빠름)
    ↓
페이지에서 이미지 객체 추출
    ↓
각 이미지를 Ollama bakllava로 분석
    ├─ 이미지 내용 설명 (영어)
    ├─ 다이어그램, 차트 분석
    └─ 수식 및 시각적 요소 설명
    ↓
텍스트 + 이미지 설명 결합
    ↓
최종 페이지 내용 생성
```

### 5. RAG 챗봇 동작 흐름
```
사용자 질문 입력
    ↓
질문을 임베딩 벡터로 변환
    ↓
ChromaDB에서 유사한 문서 검색 (PDF 페이지 또는 스크립트)
    ↓
검색된 컨텍스트와 질문을 Gemini에 전달
    ↓
AI가 컨텍스트 기반 답변 생성
    ↓
사용자에게 답변 표시 (마크다운 렌더링)
```

## 데이터 모델 구조

### 핵심 모델
- **CustomUser**: 사용자 계정 정보
- **Lecture**: 강의 메타데이터 및 처리 상태
  - `status`: 처리 상태 (`processing`: 처리 중, `completed`: 완료, `failed`: 실패)
  - `current_step`: 현재 처리 단계 (0, 1, 3, 5, 6 - 병렬 구조 반영)
  - `step_times`: 단계별 소요 시간 (JSON 형식)
  - `estimated_time_sec`: 예상 소요 시간(초, 병렬 구조 기반 계산)
  - `youtube_url`: YouTube URL (파일 업로드 대신 사용 가능)
  - `audio_file`: 오디오 파일 경로 (파일 업로드 또는 YouTube 다운로드 후)
  - `created_at`: 강의 생성 일시 (오래된 작업 감지에 사용)
- **PdfChunk**: PDF 페이지별 텍스트 내용 (텍스트 + 이미지 설명 포함)
- **Mapping**: 요약 소주제와 PDF 페이지의 의미 기반 매핑
- **ProcessingStats**: 처리 속도 통계 (ETR 예측용)
  - `audio_stt_avg_sec_per_min`: STT 평균 시간 (초/분)
  - `pdf_parsing_avg_sec_per_page`: PDF 파싱 평균 시간 (초/페이지)
  - `embedding_avg_sec_per_page`: 임베딩 평균 시간 (초/페이지)
  - `summary_avg_sec_per_min`: 요약 평균 시간 (초/분)

## 시스템 아키텍처

```
┌─────────────┐
│   사용자     │
└──────┬──────┘
       │
       ▼
┌─────────────────┐
│  Django 서버    │
│  (웹 인터페이스) │
└──────┬──────────┘
       │
       ├─────────────────┐
       │                 │
       ▼                 ▼
┌─────────────┐   ┌──────────────┐
│   SQLite    │   │   Celery     │
│  (메타데이터)│   │  (비동기 작업)│
└─────────────┘   └──────┬───────┘
                         │
                         ▼
                  ┌──────────────┐
                  │    Redis     │
                  │ (작업 큐)    │
                  └──────────────┘
                         │
                         ├─────────────────┐
                         │                 │
                         ▼                 ▼
                  ┌──────────────┐   ┌──────────────┐
                  │  Gemini API  │   │   Ollama     │
                  │ (STT/요약/   │   │ (로컬 LLM)   │
                  │  임베딩)      │   │ (PDF 이미지  │
                  └──────┬───────┘   │  분석)       │
                         │           └──────────────┘
                         │
                         ▼
                  ┌──────────────┐
                  │  ChromaDB    │
                  │ (벡터 저장소) │
                  └──────────────┘
```

## 설치 및 실행

### 필수 요구사항
- Python 3.12+
- Redis 서버
- Ollama (로컬 LLM 서버)
- FFmpeg (오디오 처리용, 선택사항)
- yt-dlp (YouTube URL을 통한 오디오 다운로드용)

### Ollama 설치 및 설정

1. **Ollama 설치**
   ```bash
   # Linux/Mac
   curl -fsSL https://ollama.com/install.sh | sh
   
   # 또는 공식 사이트에서 설치: https://ollama.com
   ```

2. **bakllava 모델 다운로드**
   ```bash
   ollama pull bakllava
   ```

3. **Ollama 서버 실행**
   ```bash
   ollama serve
   ```
   - 기본적으로 `http://localhost:11434`에서 실행됩니다
   - GPU가 있으면 자동으로 사용합니다

### 환경 변수 설정
`.env` 파일에 다음 변수를 설정해야 합니다:
- `SECRET_KEY`: Django 시크릿 키
- `GEMINI_API_KEY`: Google Gemini API 키
- `OLLAMA_BASE_URL`: Ollama 서버 URL (기본값: `http://localhost:11434`)
- `OLLAMA_MODEL`: 사용할 모델명 (기본값: `bakllava`)
- `OLLAMA_BATCH_SIZE`: PDF 처리 배치 크기 (기본값: `4`)
- `OLLAMA_TIMEOUT`: Ollama 요청 타임아웃(초) (기본값: `30`)
- `OLLAMA_MAX_RETRIES`: Ollama 요청 최대 재시도 횟수 (기본값: `2`)

### 관리자 계정 생성
관리자 대시보드에 접근하려면 `is_staff` 플래그가 있는 계정이 필요합니다:
```bash
python manage.py create_admin
```
기본 관리자 계정 (ID: `admin`, 비밀번호: `000000`)이 생성되거나 업데이트됩니다.

### 실행 방법
1. 의존성 설치: `pip install -r requirements.txt`
2. 데이터베이스 마이그레이션: `python manage.py migrate`
3. Redis 서버 실행: `redis-server`
4. Ollama 서버 실행: `ollama serve` (별도 터미널)
5. Celery 워커 실행: `celery -A config worker -l info` (별도 터미널)
6. Django 서버 실행: `python manage.py runserver`

### 작업 실패 처리 및 복구
시스템은 작업 실패를 자동으로 감지하고 처리합니다:

- **자동 실패 처리**: Celery 작업이 실패하거나 예외가 발생하면 자동으로 강의 상태를 `failed`로 업데이트
- **작업 안정성**: Celery 설정으로 작업 손실 방지 (`task_acks_late`, `task_reject_on_worker_lost`)
- **자동 오래된 작업 감지 및 실패 처리**: **Celery 워커가 시작될 때 자동으로** 다음 작업을 수행합니다:
  1. **오래된 작업 실패 처리**: 18분 이상 지난 "처리 중" 작업을 감지하고 실패로 표시
  2. 멈춘 작업은 재시작하지 않고 실패 상태로 변경하여 중복 처리나 무한 루프를 방지
- **수동 오래된 작업 감지**: 관리 명령어를 통해 수동으로 오래된 작업을 감지할 수 있음

#### 자동 감지 및 실패 처리
Celery 워커를 시작하면 (`celery -A config worker -l info`) 자동으로 다음 작업을 수행합니다:
1. 18분 이상 지난 "처리 중" 작업을 실패로 표시

별도의 설정이나 명령어 실행이 필요 없습니다. 멈춘 작업은 재시작하지 않고 실패 상태로 변경되어 데이터 일관성을 유지합니다.

#### 수동 감지 명령어
필요한 경우 수동으로도 실행할 수 있습니다:
```bash
# 기본값(18분) 이상 지난 "처리 중" 작업을 실패로 표시
python manage.py check_stuck_tasks

# 지정된 시간 이상 지난 작업만 실패로 표시
python manage.py check_stuck_tasks --minutes 10

# 실제로 변경하지 않고 확인만 (dry-run)
python manage.py check_stuck_tasks --dry-run
```

이 명령어를 주기적으로 실행하거나 cron job으로 설정하여 추가로 오래된 작업을 감지할 수 있습니다.

## 주요 특징

- **병렬 처리 최적화**: 독립적인 작업들을 동시에 실행하여 전체 처리 시간 단축
  - 병렬 그룹 1: STT + PDF 파싱 동시 실행
  - 병렬 그룹 2: 요약 + 임베딩 (임베딩은 요약 시작 후 10초 지연 시작하여 API 병목 방지)
- **API 호출 최적화**: 
  - 배치 임베딩 처리로 API 호출 횟수 최소화
  - 임베딩 지연 시작으로 요약 API와의 충돌 방지
- **API 재시도 로직**: 
  - STT 및 요약 생성 시 503 ServiceUnavailable, 서버 에러, Rate Limit 발생 시 지수 백오프로 자동 재시도
  - STT: 최대 10초 대기
  - 요약: 최대 15초 대기 (더 긴 처리 시간 고려)
- **비동기 처리**: Celery를 사용하여 파일 업로드 후 즉시 응답, 백그라운드에서 처리
- **작업 실패 처리**: 작업 실패 시 자동으로 상태를 `failed`로 업데이트하고, 오래된 "처리 중" 작업을 감지하여 실패로 표시하는 기능 제공
- **작업 안정성**: Celery 설정으로 작업 손실 방지 및 워커 중단 시 작업 재시도 지원
- **실시간 진행 상황**: 처리 중 페이지에서 4단계별 진행률 및 소요 시간 표시 (병렬 구조 반영)
- **하이브리드 PDF 처리**: PyMuPDF로 정확한 텍스트 추출 + Ollama로 이미지 분석
- **Ollama 타임아웃 및 재시도**: PDF 이미지 분석 시 강제 타임아웃 및 자동 재시도로 안정성 향상
  - **강제 타임아웃**: threading을 사용하여 Ollama API 호출에 강제 타임아웃 적용 (무한 대기 방지)
  - **페이지 전체 타임아웃**: 페이지 처리 시간이 타임아웃을 초과하면 남은 이미지 분석을 건너뛰고 다음 페이지로 진행
  - **즉시 재시도**: 타임아웃 발생 시 짧은 대기(0.5초) 후 즉시 재시도
  - **배치 처리 타임아웃**: 각 future의 시작 시간을 추적하여 개별 타임아웃 체크, 타임아웃된 future는 즉시 취소
  - **재시도 루프 내 타임아웃 체크**: 재시도 중에도 페이지 전체 타임아웃을 체크하여 무한 대기 방지
- **로컬 LLM 활용**: Ollama를 사용하여 PDF 이미지 분석 시 API 비용 절감 및 처리 속도 향상
- **YouTube URL 지원**: 파일 업로드 대신 YouTube URL을 입력하여 오디오 자동 다운로드 (10분 타임아웃)
- **Gemini API 타임아웃**: STT 및 요약 생성 시 500초 타임아웃 설정으로 무한 대기 방지
- **JSON 오류 처리 및 재시도**: 요약 생성 시 JSON 형식 오류를 자동으로 처리
- **단계별 소요 시간 추적**: 각 처리 단계의 소요 시간을 실시간으로 표시하여 성능 모니터링
- **예상 소요 시간**: 병렬 처리 구조를 반영한 정확한 처리 시간 예측
- **의미 기반 검색**: 벡터 유사도를 활용한 정확한 문서 검색
- **자동 매핑**: AI가 요약 내용과 PDF 페이지를 자동으로 연결
- **강의 공유 기능**: 
  - 로그인한 모든 사용자가 강의 페이지에 접근 가능
  - 공유하기 버튼을 통해 URL 복사 및 공유
  - 로그인하지 않은 사용자는 로그인 후 원래 페이지로 자동 리다이렉트
  - RAG 기능은 강의 소유자만 사용 가능 (권한 제어)
- **관리자 대시보드**: 
  - `is_staff` 권한 기반 접근 제어
  - ProcessingStats 실시간 통계 모니터링
  - 데이터베이스 테이블 정보 조회 (모델 이름 우선 표시, 사용 중인 컬럼만 필터링)
- **요약 파일 다운로드 기능**: 
  - 소주제별 요약본과 스크립트를 TXT 파일로 다운로드
  - 한글 파일명 지원 (RFC 5987 형식)
  - JavaScript 기반 자동 다운로드로 페이지 이동 없이 바로 다운로드
  - 요약 파일: 소주제별 요약, 타임스탬프, PDF 페이지 매핑 정보 포함
  - 스크립트 파일: 타임스탬프가 포함된 전체 스크립트
- **타임존 설정**: 한국 표준시(KST, Asia/Seoul) 사용
- **반응형 UI**: 모바일과 데스크톱 모두에서 최적화된 사용자 경험
