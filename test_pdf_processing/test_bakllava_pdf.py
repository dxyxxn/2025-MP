#!/usr/bin/env python3
"""
bakllava ëª¨ë¸ì„ ì‚¬ìš©í•œ PDF ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì…ë ¥: media_uploads/26_lecture.pdf
ì¶œë ¥: ê° í˜ì´ì§€ë³„ë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ì½˜ì†” ë° íŒŒì¼ë¡œ ì¶œë ¥
"""

import os
import sys
import json
from pathlib import Path

# Django ì„¤ì • ë¡œë“œ
BASE_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(BASE_DIR))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')

import django
django.setup()

from lecture.services import (
    init_ollama_client
)
from django.conf import settings
import fitz
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import ollama

# í…ŒìŠ¤íŠ¸ìš© ì˜ì–´ í”„ë¡¬í”„íŠ¸ (ì´ë¯¸ì§€ ë¶„ì„ìš©)
IMAGE_DESCRIPTION_PROMPT = """Describe this image in detail in English. 
Include all visible text, diagrams, charts, formulas, and visual elements.
If there are any labels, captions, or annotations, include them in your description.
Be thorough and accurate in describing what you see."""

def main():
    # PDF íŒŒì¼ ê²½ë¡œ
    pdf_path = BASE_DIR / 'media_uploads' / '26_lecture.pdf'
    
    if not pdf_path.exists():
        print(f"âŒ ì˜¤ë¥˜: PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return
    
    print("=" * 80)
    print("ğŸ“„ bakllava ëª¨ë¸ì„ ì‚¬ìš©í•œ PDF ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {pdf_path}")
    print(f"ğŸ¤– ì‚¬ìš© ëª¨ë¸: {settings.OLLAMA_MODEL}")
    print(f"âš™ï¸  ë°°ì¹˜ í¬ê¸°: {settings.OLLAMA_BATCH_SIZE}")
    print(f"ğŸŒ¡ï¸  Temperature: 0.1")
    print()
    print("ğŸ“ ì²˜ë¦¬ ë°©ì‹:")
    print("-" * 80)
    print("1. PyMuPDFë¡œ í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì •í™•í•˜ê³  ë¹ ë¦„)")
    print("2. í˜ì´ì§€ì—ì„œ ì´ë¯¸ì§€ ê°ì²´ ì¶”ì¶œ")
    print("3. ê° ì´ë¯¸ì§€ë¥¼ Ollamaë¡œ ë¶„ì„ (ì˜ì–´)")
    print("4. í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ì„¤ëª… ê²°í•©")
    print("-" * 80)
    print()
    print("ğŸ“ ì´ë¯¸ì§€ ë¶„ì„ í”„ë¡¬í”„íŠ¸:")
    print("-" * 80)
    print(IMAGE_DESCRIPTION_PROMPT)
    print("-" * 80)
    print()
    print("=" * 80)
    print()
    
    # Ollama í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    print("ğŸ”§ Ollama í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
    try:
        ollama_client = init_ollama_client()
        print("âœ… Ollama í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\n")
    except Exception as e:
        print(f"âŒ Ollama í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # PDF ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸ìš©: ì˜ì–´ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
    print("ğŸ“– PDF ì²˜ë¦¬ ì‹œì‘...\n")
    
    try:
        doc = fitz.open(str(pdf_path))
        total_pages = len(doc)
        
        def extract_images_from_page(page, pdf_doc):
            """PDF í˜ì´ì§€ì—ì„œ ì´ë¯¸ì§€ ê°ì²´ë“¤ì„ ì¶”ì¶œ"""
            images = []
            try:
                image_list = page.get_images(full=True)
                for img_index, img in enumerate(image_list):
                    try:
                        xref = img[0]
                        base_image = pdf_doc.extract_image(xref)
                        image_bytes = base_image["image"]
                        image_ext = base_image["ext"]
                        
                        # base64ë¡œ ì¸ì½”ë”©
                        import base64
                        img_base64 = base64.b64encode(image_bytes).decode('utf-8')
                        images.append({
                            'index': img_index,
                            'base64': img_base64,
                            'ext': image_ext,
                            'width': base_image.get('width', 0),
                            'height': base_image.get('height', 0)
                        })
                    except Exception as e:
                        continue
            except Exception as e:
                pass
            return images
        
        def process_single_page_test(page_num, page):
            """ë‹¨ì¼ PDF í˜ì´ì§€ ì²˜ë¦¬: í…ìŠ¤íŠ¸ ì¶”ì¶œ + ì´ë¯¸ì§€ ë¶„ì„"""
            try:
                # 1. PyMuPDFë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì •í™•í•˜ê³  ë¹ ë¦„)
                page_text = page.get_text("text").strip()
                
                # 2. í˜ì´ì§€ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
                page_images = extract_images_from_page(page, doc)
                
                # 3. ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ Ollamaë¡œ ê° ì´ë¯¸ì§€ ë¶„ì„
                image_descriptions = []
                if page_images:
                    for img_info in page_images:
                        try:
                            response = ollama_client.generate(
                                model=settings.OLLAMA_MODEL,
                                prompt=IMAGE_DESCRIPTION_PROMPT,
                                images=[img_info['base64']],
                                options={
                                    'temperature': 0.1,
                                }
                            )
                            
                            if hasattr(response, 'response'):
                                img_description = response.response.strip()
                            elif isinstance(response, dict):
                                img_description = response.get('response', '').strip()
                            else:
                                img_description = str(response).strip()
                            
                            if img_description:
                                image_descriptions.append(f"[Image {img_info['index'] + 1}]: {img_description}")
                        except Exception as e:
                            image_descriptions.append(f"[Image {img_info['index'] + 1}]: Error analyzing image - {str(e)}")
                
                # 4. í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì„¤ëª… ê²°í•©
                combined_content = []
                if page_text:
                    combined_content.append("=== Text Content ===")
                    combined_content.append(page_text)
                
                if image_descriptions:
                    if combined_content:
                        combined_content.append("\n")
                    combined_content.append("=== Image Descriptions ===")
                    combined_content.extend(image_descriptions)
                
                final_text = "\n".join(combined_content) if combined_content else ""
                
                return (page_num + 1, final_text)
            except Exception as e:
                print(f"í˜ì´ì§€ {page_num + 1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()
                return (page_num + 1, "")
        
        pdf_texts = []
        
        batch_size = settings.OLLAMA_BATCH_SIZE
        print(f"ì´ {total_pages}í˜ì´ì§€ë¥¼ ë°°ì¹˜ í¬ê¸° {batch_size}ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
        print("(í…ìŠ¤íŠ¸ëŠ” ì¦‰ì‹œ ì¶”ì¶œ, ì´ë¯¸ì§€ê°€ ìˆëŠ” í˜ì´ì§€ë§Œ Ollamaë¡œ ë¶„ì„)\n")
        
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        for batch_start in tqdm(range(0, total_pages, batch_size), desc="PDF í˜ì´ì§€ ë°°ì¹˜ ì²˜ë¦¬"):
            batch_end = min(batch_start + batch_size, total_pages)
            batch_pages = list(range(batch_start, batch_end))
            
            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë°°ì¹˜ ë‚´ í˜ì´ì§€ë“¤ ì²˜ë¦¬
            with ThreadPoolExecutor(max_workers=batch_size) as executor:
                futures = {
                    executor.submit(process_single_page_test, page_num, doc[page_num]): page_num
                    for page_num in batch_pages
                }
                
                # ì™„ë£Œëœ ì‘ì—…ë¶€í„° ê²°ê³¼ ìˆ˜ì§‘
                for future in as_completed(futures):
                    try:
                        result = future.result()
                        pdf_texts.append(result)  # ë¹ˆ í…ìŠ¤íŠ¸ë„ í¬í•¨
                    except Exception as e:
                        page_num = futures[future]
                        print(f"í˜ì´ì§€ {page_num + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        pdf_texts.append((page_num + 1, ""))
        
        doc.close()
        
        # í˜ì´ì§€ ë²ˆí˜¸ ìˆœìœ¼ë¡œ ì •ë ¬
        pdf_texts.sort(key=lambda x: x[0])
        
        print(f"PDF parsing complete. {len(pdf_texts)} pages processed.\n")
    except Exception as e:
        print(f"âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return
    
    if not pdf_texts:
        print("âš ï¸  ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    print(f"ì´ í˜ì´ì§€ ìˆ˜: {len(pdf_texts)}")
    print(f"í…ìŠ¤íŠ¸ê°€ ìˆëŠ” í˜ì´ì§€: {sum(1 for _, text in pdf_texts if text.strip())}")
    print()
    
    # ê° í˜ì´ì§€ë³„ ê²°ê³¼ ì¶œë ¥
    output_dir = BASE_DIR / 'test_pdf_processing' / 'output'
    output_dir.mkdir(exist_ok=True)
    
    output_file = output_dir / '26_lecture_extracted_bakllava.txt'
    json_file = output_dir / '26_lecture_extracted_bakllava.json'
    
    print("=" * 80)
    print("ğŸ“ í˜ì´ì§€ë³„ ì¶”ì¶œ ê²°ê³¼")
    print("=" * 80)
    
    results = []
    with open(output_file, 'w', encoding='utf-8') as f:
        for page_num, text in pdf_texts:
            page_info = {
                'page_num': page_num,
                'text': text,
                'text_length': len(text),
                'has_text': bool(text.strip())
            }
            results.append(page_info)
            
            print(f"\n[í˜ì´ì§€ {page_num}]")
            print("-" * 80)
            if text.strip():
                print(f"í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì")
                print(f"\nì „ì²´ ë‚´ìš©:")
                print("-" * 80)
                print(text)  # ì „ì²´ ë‚´ìš© ì¶œë ¥
                print("-" * 80)
                
                # íŒŒì¼ì— ì €ì¥
                f.write(f"\n{'='*80}\n")
                f.write(f"í˜ì´ì§€ {page_num}\n")
                f.write(f"í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì\n")
                f.write(f"{'='*80}\n\n")
                f.write(text)
                f.write(f"\n\n")
            else:
                print("âš ï¸  í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                f.write(f"\n{'='*80}\n")
                f.write(f"í˜ì´ì§€ {page_num} - í…ìŠ¤íŠ¸ ì—†ìŒ\n")
                f.write(f"{'='*80}\n\n")
    
    # JSON í˜•ì‹ìœ¼ë¡œë„ ì €ì¥
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump({
            'pdf_path': str(pdf_path),
            'model': 'bakllava',
            'total_pages': len(pdf_texts),
            'pages': results
        }, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 80)
    print("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
    print("=" * 80)
    print(f"ğŸ“„ í…ìŠ¤íŠ¸ íŒŒì¼: {output_file}")
    print(f"ğŸ“‹ JSON íŒŒì¼: {json_file}")
    print()
    
    # í†µê³„ ì •ë³´
    total_chars = sum(len(text) for _, text in pdf_texts)
    avg_chars_per_page = total_chars / len(pdf_texts) if pdf_texts else 0
    
    print("=" * 80)
    print("ğŸ“ˆ í†µê³„ ì •ë³´")
    print("=" * 80)
    print(f"ì´ ë¬¸ì ìˆ˜: {total_chars:,}ì")
    print(f"í˜ì´ì§€ë‹¹ í‰ê·  ë¬¸ì ìˆ˜: {avg_chars_per_page:,.0f}ì")
    print(f"í…ìŠ¤íŠ¸ê°€ ìˆëŠ” í˜ì´ì§€ ë¹„ìœ¨: {sum(1 for _, text in pdf_texts if text.strip()) / len(pdf_texts) * 100:.1f}%")
    print("=" * 80)

if __name__ == '__main__':
    main()

